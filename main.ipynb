{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since SIFT functions are removed in OpenCV 4.x due to patent issues 3.4.2 version is used \n"
     ]
    }
   ],
   "source": [
    "# Mustafa Ghanim , Department of Electrical-Electronics Engineering \n",
    "# Import the required packages\n",
    "import numpy as np\n",
    "import pickle # built-in Python based structure serialization function to save/load dictionary\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "#from IPython.core.debugger import set_trace\n",
    "from sklearn.svm import SVC\n",
    "from scipy.cluster.vq import vq\n",
    "import os.path as osp\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "from sklearn.cluster import MeanShift,estimate_bandwidth\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "print('Since SIFT functions are removed in OpenCV 4.x due to patent issues {} version is used '.format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all required functions\n",
    "\n",
    "# Not used but useful functions to normalize and gray-scale images\n",
    "def load_image(path):\n",
    "    return im2single(cv2.imread(path))[:, :, ::-1]\n",
    "\n",
    "\n",
    "def load_image_gray(path):\n",
    "    img = load_image(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def gridSIFT(img, step = 30, size = 40,display = False,is_print = False):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    rows, cols = gray.shape\n",
    "    kp = []\n",
    "    patch_cnt = 0\n",
    "    for x in range(step,cols,step):\n",
    "        for y in range(step,rows,step):\n",
    "            patch_cnt+= 1\n",
    "            kp.append(cv2.KeyPoint(x, y, size))\n",
    "    kp, des = sift.compute(img, kp)\n",
    "    if(display == True):\n",
    "            org_img = img.copy()\n",
    "            I = cv2.drawKeypoints(img,kp,img)\n",
    "            plt.figure(figsize=(15,15))\n",
    "            plt.subplot(121), plt.imshow(cv2.cvtColor(org_img, cv2.COLOR_BGR2RGB))\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(122), plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            plt.title('Patch Features on The Image')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    if(is_print == True):\n",
    "        print('Total number of image patches in this grid = {} (size: {} x {})'.format(patch_cnt,size,size))\n",
    "    return kp,des\n",
    "\n",
    "\n",
    "def my_means_shift(X,kps,bandwidth = 15):\n",
    "    \n",
    "    print('Means-shift algorithm starts ..')\n",
    "    kps_locations = []\n",
    "    for i in kps:\n",
    "        kps_locations.append(i.pt)\n",
    "   \n",
    "    ms = MeanShift(bandwidth = bandwidth,bin_seeding = True)\n",
    "    ms.fit(kps_locations)\n",
    "    labels = ms.labels_\n",
    "    kps_centers = ms.cluster_centers_\n",
    "    labels_unique = np.unique(labels)\n",
    "    estimated_K = len(labels_unique)\n",
    "    n_clusters = estimated_K\n",
    "    print('The Estimated Number of Clusters Using  Means-Shift = {}'.format(estimated_K))\n",
    "    SIFT_centers = []\n",
    "    for i in labels_unique:\n",
    "        labels_corresp = np.where(labels == i)[0]\n",
    "        SIFT_sum = 0\n",
    "        for j in labels_corresp:\n",
    "            SIFT_sum+= X[j]\n",
    "        SIFT_centers.append(SIFT_sum/len(labels_corresp))\n",
    "\n",
    "    return np.array(SIFT_centers),estimated_K\n",
    "        \n",
    "def features_size(image_paths,step,size,keypoints_thres = 500,grid_sift = False,is_print = False):\n",
    "    sift = cv2.xfeatures2d.SIFT_create(keypoints_thres)\n",
    "    cnt = 0\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        if(grid_sift == True):\n",
    "            \n",
    "            kp,descriptors= gridSIFT(img,step = step, size = size,is_print = is_print) \n",
    "        else:  \n",
    "            ## Compute the descriptors\n",
    "            (kp, descriptors) = sift.detectAndCompute(gray, None)\n",
    "\n",
    "        ## Compute the final array of descriptors\n",
    "        try:\n",
    "                X = np.concatenate((X,descriptors))\n",
    "                kps = np.concatenate((kps,kp))\n",
    "        except:\n",
    "                X = descriptors\n",
    "                kps = kp\n",
    "    print('The size of SIFT discriptors for this experiment = {} x {}'.format(X.shape[0],X.shape[1]))            \n",
    "    print('The average SIFT discriptors  per image = {:.2f}'.format(X.shape[0]/len(image_paths)))\n",
    "                \n",
    "    return kps,X            \n",
    "\n",
    "def compute_dictionary(image_paths, K,keypoints_thres = 500, grid_sift = False, means_shift = False,means_shift_clustering = False,is_print = False):\n",
    "    ## Using sift from opencv\n",
    "    ## set no of keypoints \n",
    "    sift = cv2.xfeatures2d.SIFT_create(keypoints_thres)\n",
    "    cnt = 0\n",
    "    for path in image_paths:\n",
    "        cnt+= 1\n",
    "        if(cnt % 30 == 0):\n",
    " \n",
    "            print('SIFTs Extracted of {} train images, {} many images left'.format(cnt,len(image_paths) - cnt))\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        if(grid_sift == True):\n",
    "            \n",
    "            kp,descriptors= gridSIFT(img,is_print = is_print)\n",
    "           \n",
    "        else:  \n",
    "            ## Compute the descriptors\n",
    "            (kp, descriptors) = sift.detectAndCompute(gray, None)\n",
    "\n",
    "        ## Compute the final array of descriptors\n",
    "        try:\n",
    "                X = np.concatenate((X,descriptors))\n",
    "                kps = np.concatenate((kps,kp))\n",
    "        except:\n",
    "                X = descriptors\n",
    "                kps = kp\n",
    "    print('Total number of SIFT descriptors = {}, {} per image as average'.format(X.shape[0],X.shape[0]/len(image_paths)))\n",
    "    #Clustering \n",
    "    print('Starting clustering operations ..')\n",
    "    # Means-Shift\n",
    "  #  bandwidth = estimate_bandwidth(X, quantile=0.2)\n",
    "   # print('The Estimated Bandwidth Parameter for Means-Shift = {}'.format(bandwidth))\n",
    "    if(means_shift == True and means_shift_clustering == True):\n",
    "        print('K estimation and clustering SIFTs are done with Means-Shift')\n",
    "        SIFT_centers, n_clusters = my_means_shift(X,kps)\n",
    "        return SIFT_centers \n",
    "    elif(means_shift == True and means_shift_clustering == False):\n",
    "        print('K estimation by Means-Shift and clustering by Kmeans')\n",
    "        SIFT_centers, n_clusters = my_means_shift(X,kps)\n",
    "        kmeans = KMeans(n_clusters, random_state=0).fit(X)\n",
    "        dictionary = kmeans.cluster_centers_\n",
    "        return dictionary \n",
    "    else:\n",
    "        print('Used Number of clusters by user input = {}'.format(K))\n",
    "        kmeans = KMeans(K, random_state=0).fit(X)\n",
    "        dictionary = kmeans.cluster_centers_\n",
    "        return dictionary \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_calc_and_feature_quan(image_paths, dictionary_filename,grid_sift = False,keypoints_thres = 500,tfidf_opt = False,is_print = False):\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create(keypoints_thres)\n",
    "\n",
    "    with open(dictionary_filename, 'rb') as f:\n",
    "        dictionary = pickle.load(f)\n",
    "    print('Used dictionary: {}'.format(dictionary_filename))\n",
    "  # # Histogram of counts from the assignments\n",
    "\n",
    "    def calc_histogram(assignments):\n",
    "\n",
    "        hist = [0 for i in range(dictionary.shape[0])]\n",
    "\n",
    "        for i in assignments:\n",
    "            hist[i] += 1\n",
    "\n",
    "        hist = [i / sum(hist) for i in hist]\n",
    "\n",
    "        return hist\n",
    "    qunatized_features = []\n",
    "    # frequency–inverse document frequency, an optimization method (extra for this project) \n",
    "    # can be used to optimize some experiments by giving statistical weights according to frequency-term importance\n",
    "    # Inverse Data Frequency (IDF) ratio is found in log format. \n",
    "    \n",
    "    def tfidf(tf_hists):\n",
    "        epsilon = 1e-6\n",
    "\n",
    "        tfidf = []\n",
    "        df = []\n",
    "        T = len(tf_hists)\n",
    "\n",
    "        for i in range(dictionary.shape[0]):\n",
    "            temp = 0\n",
    "            for hist in tf_hists:\n",
    "                if hist[i] > 0:\n",
    "                    temp += 1\n",
    "            df.append(temp)\n",
    "        idf = np.log([T / max(i,epsilon) for i in df])\n",
    "\n",
    "        for hist in tf_hists:\n",
    "            tfidf.append(hist * idf)\n",
    "\n",
    "        return np.array(tfidf)\n",
    "\n",
    "    for path in image_paths:\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute the patch-based (dense) sift descriptors\n",
    "        if(grid_sift == True):\n",
    "            kp,descriptors = gridSIFT(img,is_print = is_print)\n",
    "        else:  \n",
    "            ## Compute the keypoint-based descriptors\n",
    "            (_, descriptors) = sift.detectAndCompute(gray, None)\n",
    "        # Assign the nearest code from codebook (dictionary) to the corresponding observation (feature quntization)\n",
    "        # Nearest neighbor step\n",
    "        (assignments, _) = vq(descriptors, dictionary)\n",
    "\n",
    "        qunatized_features.append(calc_histogram(assignments))\n",
    "    if(tfidf_opt == True):\n",
    "        print('Optimization is done with tf–idf')\n",
    "        return tfidf(qunatized_features) \n",
    "    else: \n",
    "        return qunatized_features\n",
    "\n",
    "\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "\n",
    "    ##Linear svm (One vs rest)\n",
    "    # C is the regularization parameter  \n",
    "    clf = LinearSVC(random_state= 0, tol=1e-4,C=7)\n",
    "\n",
    "    ## Fit the model\n",
    "    clf.fit(train_image_feats, train_labels)\n",
    "\n",
    "    ## Predict\n",
    "    predicted_categories = clf.predict(test_image_feats)\n",
    "\n",
    "    return predicted_categories \n",
    "\n",
    "# this function is manually implemented to calculate CM, it gives the same result with the built-in function. \n",
    "def find_confusion_matrix(test_labels,predicted_labels):\n",
    "    # Do not show +0e expressions when importing labels form CSV file\n",
    "    np.set_printoptions(suppress=True) \n",
    "\n",
    "    labels=np.unique(predicted_labels)\n",
    "    N = len(labels) # N is how many different types of labels are there. \n",
    "    confusion_matrix = np.zeros((N, N))\n",
    "    \n",
    "    for i in range(len(predicted_labels)):\n",
    "        confusion_matrix[int(test_labels[i])][int(predicted_labels[i])] +=1\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def classification_results(train_image_paths, test_image_paths, train_labels, test_labels,\n",
    "    categories,predicted_categories):\n",
    "\n",
    "    cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "    # confusion matrix\n",
    "    out_true = [cat2idx[cat] for cat in test_labels]\n",
    "    out_predicted = [cat2idx[cat] for cat in predicted_categories]\n",
    "    # you can use the manually implemented CM matrix function as well\n",
    "    conf_mat = confusion_matrix(out_true, out_predicted) #find_confusion_matrix(out_true,out_predicted)\n",
    "    # Normalized Confusion matrix\n",
    "    conf_mat = conf_mat.astype(np.float) / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "   \n",
    "    valid_acc = np.mean(np.diag(conf_mat))\n",
    "    # Regular CM:\n",
    "    conf_mat = 100 * conf_mat\n",
    "    fig, ax = plt.subplots()\n",
    "   # plt.figure()\n",
    "    im = ax.imshow(conf_mat, interpolation='nearest', cmap=plt.cm.Reds)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    plt.title('Validation Accuracy = {:4.2f}%'.format(valid_acc*100))\n",
    "    tick_marks = np.arange(len(categories))\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(tick_marks, categories, rotation=45)\n",
    "    plt.yticks(tick_marks, categories)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('Numeric Representation of The Found Confusion Matrix ..')\n",
    "    print(conf_mat)\n",
    "    FP = conf_mat.sum(axis=0) - np.diag(conf_mat)  \n",
    "    FN = conf_mat.sum(axis=1) - np.diag(conf_mat)\n",
    "    print(\"Total False Positive Values = {}\".format(np.sum(FP)))\n",
    "    print(\"Total Flase Negative Values = {}\".format(np.sum(FN)))\n",
    "    return conf_mat \n",
    "\n",
    "def show_predicted_image(test_label,predicted_label,image_path):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    image = cv2.imread(image_path)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.title('Actual Category : {} --> Predicted Category: {}'.format(test_label,predicted_label))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(data_path, train_categories, validation_categories, img_format='jpg'):\n",
    "\n",
    "    train_image_paths = []\n",
    "    test_image_paths = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for cat in train_categories:\n",
    "        \n",
    "        # train\n",
    "        pth = osp.join(data_path, cat, '*.{:s}'.format(img_format))  \n",
    "        pth = glob(pth)  \n",
    "        shuffle(pth)\n",
    "        train_image_paths.extend(pth)\n",
    "        train_labels.extend([cat.partition('_')[0]]*len(pth))\n",
    "    for cat in validation_categories:    \n",
    "        # test\n",
    "        pth = osp.join(data_path, cat, '*.{:s}'.format(img_format))\n",
    "        pth = glob(pth)\n",
    "        shuffle(pth)\n",
    "        test_image_paths.extend(pth)\n",
    "        test_labels.extend([cat.partition('_')[0]]*len(pth))\n",
    "\n",
    "    return train_image_paths, test_image_paths, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 160 train and 400 validation images ready to be process ..\n",
      "There are 4 different classes in this project \n"
     ]
    }
   ],
   "source": [
    "# Reading validation and train images\n",
    "\n",
    "train_categories = ['airplanes_train','cars_train','faces_train','motorbikes_train']\n",
    "\n",
    "validation_categories = ['airplanes_validation','cars_validation','faces_validation','motorbikes_validation']\n",
    "\n",
    "categories = ['airplanes','cars','faces','motorbikes']\n",
    "working_path = 'E:\\My Google Drive\\OZU\\Spring2020\\Computer Vision\\Projects\\Final Project\\Final-Assignment_data\\Final-Assignment data'\n",
    "dataset_folder_name = 'dataset'\n",
    "data_path = osp.join(working_path, dataset_folder_name)\n",
    "\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = read_dataset(data_path,train_categories,validation_categories)\n",
    "print('There are {} train and {} validation images ready to be process ..'.format(len(train_image_paths),len(test_image_paths)))\n",
    "print('There are {} different classes in this project '.format(len(np.unique(train_labels))))\n",
    "# all train/validation category folders should be under dataset_folder_name (as given in LMS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Bag- of - Features Dictionary\n",
      "No existing visual word dictionary found. Computing one from training images\n",
      "SIFTs Extracted of 30 train images, 130 many images left\n",
      "SIFTs Extracted of 60 train images, 100 many images left\n",
      "SIFTs Extracted of 90 train images, 70 many images left\n",
      "SIFTs Extracted of 120 train images, 40 many images left\n",
      "SIFTs Extracted of 150 train images, 10 many images left\n",
      "Total number of SIFT descriptors = 19288, 120.55 per image as average\n",
      "Starting clustering operations ..\n",
      "Used Number of clusters by user input = 5\n",
      "test.pkl saved\n"
     ]
    }
   ],
   "source": [
    "print('Computing Bag- of - Features Dictionary')\n",
    "\n",
    "dictionary_filename = 'test.pkl'\n",
    "if not osp.isfile(dictionary_filename):\n",
    "    # Construct the vocabulary\n",
    "    print('No existing visual word dictionary found. Computing one from training images')\n",
    "    dictionary_size = 5  # It's same with clusters number, not important when using means-shift\n",
    "    # if means_shift is TRUE and means_shift_clustering is TRUE then all clustering operations are done with Means-Shift\n",
    "    # if if means_shift is TRUE and means_shift_clustering is FALSE then K found by MS will be used in Kmeans\n",
    "    # if both variables are FALSE then you have to consider dictionary_size as the Kmeans actual output size \n",
    "    dictionary = compute_dictionary(train_image_paths, dictionary_size,grid_sift = True,means_shift = False,means_shift_clustering= False)\n",
    "    with open(dictionary_filename, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "        print('{:s} saved'.format(dictionary_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dictionary: test.pkl\n",
      "Used dictionary: test.pkl\n"
     ]
    }
   ],
   "source": [
    "dictionary_filename = 'test.pkl'\n",
    "\n",
    "train_image_feats = hist_calc_and_feature_quan(train_image_paths, dictionary_filename,grid_sift = False,tfidf_opt=  False)\n",
    "test_image_feats = hist_calc_and_feature_quan(test_image_paths, dictionary_filename,grid_sift = False,tfidf_opt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Classification and Confusion Matrix Results')\n",
    "predicted_categories = svm_classify(train_image_feats, train_labels, test_image_feats)\n",
    "# %matplotlib inline\n",
    "\n",
    "cm = classification_results(train_image_paths, test_image_paths, train_labels, test_labels, categories,\n",
    "             predicted_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
